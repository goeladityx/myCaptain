import sqlite3
from urllib.request import Request, urlopen
from bs4 import BeautifulSoup
import pandas as pd
import argparse

def connect(dbname):
    conn= sqlite3.connect(dbname)
    conn.execute("CREATE TABLE IF NOT EXISTS OYO_HOTELS (NAME TEXT, ADDRESS TEXT, PRICE INT, RATING FLOAT, AMENITIES TEXT)")
    print("table created!")
    conn.close()

def insert_db(dbname, values):
    conn= sqlite3.connect(dbname)
    insert_sql= "INSERT INTO OYO_HOTELS (NAME, ADDRESS, PRICE, RATING, AMENITIES) VALUES(?, ?, ?, ?, ?)"
    conn.execute(insert_sql, values)
    conn.commit()
    conn.close()

def retrieve(dbname):
    conn= sqlite3.connect(dbname)
    cur= conn.cursor()
    cur.execute("SELECT * FROM OYO_HOTELS")
    table_data= cur.fetchall()
    for record in table_data:
        print(record)
    conn.close()
    
"""
parser= argparse.ArgumentParser()
parser.add_argument("--page_max", help="Enter the maximum number of pages", type=int)
args= parser.parse_args()
"""

dbname= input("Enter the name of database: ")
connect(dbname)
req = Request('https://www.oyorooms.com/search?checkin=03%2F03%2F2021&checkout=04%2F03%2F2021&city=Bangalore&country=belvilla&coupon=&filters%5Bcity_id%5D=4&guests=2&location=Bangalore%2C%20Karnataka%2C%20India&roomConfig%5B%5D=2&rooms=1&searchType=city', headers={'User-Agent': 'Mozilla/5.0'})
content = urlopen(req).read()

soup= BeautifulSoup(content, "html.parser")
all_hotels= soup.find_all("div", {"class": "hotelCardListing"})
scraped_info=[]

#page_num_max= args.page_max

for hotel in all_hotels:
    hotel_info={}
    hotel_info["name"]= hotel.find("h3", {"class": "listingHotelDescription__hotelName"}).text
    hotel_info["address"]= hotel.find("span", {"itemprop": "streetAddress"}).text
    hotel_info["price"]= hotel.find("span", {"class": "listingPrice__finalPrice"}).text
    #hotel_rating= hotel.find("span", {"class": "hotelRating__rating"}).text
    try:
        hotel_info["rating"]= hotel.find("span", {"class": "hotelRating__rating"}).text
    except AttributeError:
        pass
    
    parent_amenities= hotel.find("div", {"class": "amenityWrapper"})
    amenities_list=[]
    
    for amenity in parent_amenities.find_all("div", {"class": "amenityWrapper__amenity"}):
        amenities_list.append(amenity.find("span", {"class": "d-body-sm"}).text.strip())
    
    hotel_info["amenities"]= ", ".join(amenities_list[:-1])
    
    scraped_info.append(hotel_info)
    insert_db(dbname, tuple(hotel_info.values()))
    #print(hotel_info)
    
retrieve(dbname)
#dataFrame= pd.DataFrame(scraped_info)
#dataFrame.to_csv("Oyo.csv")
